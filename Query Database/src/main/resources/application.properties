spring.application.name=SpringAi
spring.docker.compose.lifecycle-management=start-only
logging.level.org.springframework.ai.chat.client.advisor=DEBUG
spring.threads.virtual.enabled=true
#spring.datasource.url=jdbc:mysql://localhost:3307/AppleDbAi
spring.datasource.url=jdbc:mysql://localhost:3307/AppleDbAi?createDatabaseIfNotExist=true&autoReconnect=true&useSSL=false&useServerPrepStmts=false&rewriteBatchedStatements=true&allowPublicKeyRetrieval=true&logger=com.mysql.cj.log.Slf4JLogger&profileSQL=true
spring.datasource.username=shri
spring.datasource.password=shrishri
# The default Ollama Model in Spring Ai is mistral, but it can be changed by setting the below property. make sure to download the same model in entrypoint.sh file
spring.ai.ollama.chat.options.model=codellama
# If running the Ollama Docker Instance separately, then set this property
spring.docker.compose.enabled=false
spring.sql.init.mode=always
spring.sql.init.data-locations=classpath:apple_data.sql
spring.sql.init.schema-locations=classpath:apple_schema.sql