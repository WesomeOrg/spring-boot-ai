spring.application.name=SpringAi
spring.docker.compose.lifecycle-management=start-only
spring.threads.virtual.enabled=true
#documentDirectory=C:/Users/shriksha/Music/
documentDirectory=classpath:/documents
inputFilenamePattern=*.{json,st,xml,pdf,mp3,mp4,docx,txt,pages,csv}
# The default Ollama Model in Spring Ai is mistral, but it can be changed by setting the property. use the same model in entrypoint.sh file
#spring.ai.ollama.chat.options.model=llama3.1
# If running the Ollama Docker Instance separately, then set this property
spring.docker.compose.enabled=false